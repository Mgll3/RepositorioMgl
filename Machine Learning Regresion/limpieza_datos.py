# -*- coding: utf-8 -*-
"""Limpieza_datos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p4KTBehH2RBwoloDN4-GOrGYBo_vM95K

#  Creación de modelos de machine learning para análisis y predicciones de muertes prenatales en embarazos de Medellín
"""

!pip install --upgrade category_encoders

# Importamos librerías
import numpy as np
import pandas as pd
from sklearn.svm import OneClassSVM
from category_encoders import BinaryEncoder
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
# Librería para guardar y cargar modelos
import pickle

"""# Limpieza de datos"""

# Importamos los datos de csv en un dataframe de pandas
dataBruto = pd.read_csv("embarazos_medellin.csv", sep = ";")
dataBruto.drop('ID', axis=1, inplace=True) # Eliminamos columna id

# Columnas del dataframe
dataBruto.info()

# Ejemplo de los datos
display(dataBruto.head())

# Eliminación de datos duplicados
data = dataBruto.drop_duplicates()
# Cambiamos datos faltantes por su moda

num_nulls = data.isna().any(axis=1).sum() #numero de registros con datos faltantes


imputer = SimpleImputer(strategy='most_frequent')
columnas_faltantes = data.columns[data.isna().any()].tolist() # Selecciona las columnas con valores faltantes

data[columnas_faltantes] = imputer.fit_transform(data[columnas_faltantes])
# Calculamos porcentaje de datos eliminados
tamaño_original = dataBruto.shape[0]
tamaño_actual = data.shape[0]
print(f"Tamaño original = {tamaño_original} \n Tamaño actual {tamaño_actual} \n porcentaje de datos eliminados = {100-(tamaño_actual*100/tamaño_original)}% ")
print("numero de registros con datos nulos", num_nulls)
#, "nuevo ", new_data_nulls
print("porcentaje de datos faltantes", (1-tamaño_actual/tamaño_original))

#calculamos el numero de muertos y vivos
producto_column = data["TIPO_PRODUCTO"]
muertos = len([ p for p in producto_column if p == "Producto muerto"])
vivos = len([ p for p in producto_column if p == "Producto vivo"])
# Gráfico
nombres_barras = ['Muertos', 'Vivos']
datos_barras = [muertos, vivos]
plt.bar(nombres_barras, datos_barras)
plt.title('Comparación de muertos y vivos')
plt.xlabel('Estado')
plt.ylabel('Número de personas')
plt.show()

# Eliminamos columnas con datos no aportantes al ámbito
data.drop(["CODPTORE", "CODMUNRE", "fecha_nacimiento"], axis=1, inplace=True) # Eliminamos departamento y municipio, pues todos los datos son en Medellín y la fecha ya es dada por otras columnas
# Departamento y municipio son redundantes pues esta base de datos es en Medellín , y fecha de nacimiento se encuentra en otras tablas
cols_cat = data.columns.tolist()
for col in cols_cat: # Miramos el numero de niveles que tiene cada columna
  print(f'Columna {col}: {data[col].nunique()} subniveles')

for col in data.columns:
  print(col)
  counts = data[col].value_counts()
  print(counts)

"""El número de subniveles de las columnas  categóricas  año, mes, tipo producto, sexo, seguridad social, codigo de comuna, aporte embarazo se ajustan al número dado por la base de datos.

Por la alta cantidad de categorías de BARRIO_RES y IDCLASAADMI que son barrio de residencia y el nombre de la entidad administradora en salud respectivamente, es inviable encontrar datos mal copiados.
"""

# Transformar datos categóricos a numéricos usando binary encoding
display(data["BARRIO_RES"])
col_categoricas = ["IDCLASADMI", "BARRIO_RES"] # Variables categóricas que no han sido procesadas
encoders = []
for column_name in col_categoricas:
  column = data[column_name] # Guardamos la columna
  binary_encoder = BinaryEncoder(cols=[column_name]) # Creamos el objetos
  binary_encoder.fit(column) # Entrenamos con la columna
  encoders.append(binary_encoder) # Guardamos en la lista
  columna_encoder = binary_encoder.transform(column) # Creamos las columnas codificadas
  data = pd.concat([data, columna_encoder], axis=1) # Guardamos las columnas codificadas en el dataframe
  data.drop([column_name],axis=1, inplace=True )

# Transformar dato categórico de "tipo producto" a numérico
# Creamos un diccionario de reemplazo
reemplazo = {"Producto vivo": 0, "Producto muerto": 1}

# Usamos la función replace()
columna_tipo_producto = data["TIPO_PRODUCTO"]
data["TIPO_PRODUCTO"] = columna_tipo_producto.replace(reemplazo)


data.info()

#modelo de caja con los datos de la edad. tiene que mostrar que los datos sí son atípicos

import matplotlib.pyplot as plt
edad = data["EDAD_MADRE"]

# crear un diagrama de cajas
plt.boxplot(edad)

# agregar etiquetas
plt.title("Diagrama de cajas de edad")
plt.ylabel("Y")

# mostrar el diagrama
plt.show()

# Eliminamos datos atípicos restringiendo el rango de edad a
tamaño_antes = data.shape
data.drop(data[(data['EDAD_MADRE'] < 12) | (data['EDAD_MADRE'] > 54)].index, inplace=True)
# Se eliminaron los mayores por 54, por que no encontraron datos nuevos entre el rango de 54 y 98
# Como se encontraron solo 6 datos menores a 12 años se eliminan este rango
tamaño_nuevo = data.shape
print(tamaño_antes, tamaño_nuevo)

"""# Guardamos los datos"""

# Guardamos los datos limpiados
data.to_csv('embarazos_medellin_limpios.csv', index=False)

# Guardamos los modelos de codificación

file_name = 'binary_encoder_IDCLASADMI.pkl' # Nombre del archivo
with open(file_name, 'wb') as file:
    pickle.dump(encoders[0], file) # Guardamos el modelo

file_name= 'binary_encoder_BARRIO_RES.pkl' # Nombre del archivo
with open(file_name, 'wb') as file:
    pickle.dump(encoders[1], file) # Guardamos el modelo

# Cargamos el archivo
with open(file_binary_barrio , 'rb') as file:
    modelo_cargado = pickle.load(file)

# Codificación de las columnas usando el objeto de binary encoder entrenado
modelo_cargado.inverse_transform(columna_encode.head())



