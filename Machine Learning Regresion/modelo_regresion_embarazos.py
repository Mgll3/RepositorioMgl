# -*- coding: utf-8 -*-
"""Modelo_Regresion_embarazos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GmznDl6AKmnxFXoUwPX7R8f0bmBgXw_g
"""

!pip install --upgrade category_encoders

"""#Creación del modelo de machine learning para prediccion de muertes prenatales usando el algoritmo de regresión logística

"""

# Importamos librerías
import pandas as pd
from pandas import read_csv as read
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression as Regression
from sklearn.tree import DecisionTreeClassifier as tree
from category_encoders import BinaryEncoder
from sklearn.metrics import accuracy_score, auc, f1_score ,recall_score, roc_curve, average_precision_score,precision_recall_curve, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import roc_curve, RocCurveDisplay
import matplotlib.pyplot as plt
from sklearn.metrics import PrecisionRecallDisplay
import plotly.express as px



# Librerías para guardar y cargar modelos
import pickle
import joblib

"""Cargamos Datos y asignamos columnas"""

# Cargamos datos limpios
data = pd.read_csv("embarazos_medellin_limpios.csv", sep = ",")
display(data)

"""Separación de datos

"""

# creacion de class_weight
producto_column = data["TIPO_PRODUCTO"]
muertos = len([ p for p in producto_column if p == 1])
vivos = len([ p for p in producto_column if p == 0])

#definimos el diccionario para el peso de cada dato usando esta formula
# wj=n_muestras / (n_clases * n_muestrasj)  donde wj es el peso de la clase j
# n_muestras el numero de registros totales y n_muestrasj es el numero de muestras de la clase j

classWeight = {
  0: (muertos+vivos)/(2*vivos),
  1: (muertos+vivos)/(2*muertos)
}
print(vivos, muertos)

# Separamos datos
Y= data[['TIPO_PRODUCTO']] # Target u objetivo
X = data.drop("TIPO_PRODUCTO", axis = 1)

# Separación en datos de entrenamiento y datos de validación
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7)

# 70% de los datos son para entrenar
# 30% de los datos son para validar

"""Creación de modelos"""

#Modelo: LogisticRegression
#Mejor combinación de hiperparámetros: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}
#Mejor puntuación de validación cruzada: 0.9668811923060374
modelo_regression_logistica = Regression(class_weight=classWeight, max_iter=2000,
                                         C=1,
                                         penalty = "l2",
                                         solver= "sag") # modelo creado con el algoritmo regresion logistica
#Modelo: DecisionTreeClassifier
#Mejor combinación de hiperparámetros: {'criterion': 'gini', 'max_depth': 3, 'max_features': None}
#Mejor puntuación de validación cruzada: 0.9830346053275179
modelo_decision_tree = DecisionTreeClassifier(class_weight=classWeight,
                                              criterion = "gini",
                                              max_depth=3,
                                              max_features=None) # modelo creado con el algoritmo decision tree
#Modelo: RandomForestClassifier
#Mejor combinación de hiperparámetros: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 200}
#Mejor puntuación de validación cruzada: 0.9858218010876124
modelo_random_forest = RandomForestClassifier(class_weight=classWeight,
                                              criterion = "entropy",
                                              max_depth=None,
                                              n_estimators=200) # modelo creado con el algoritmo random forest
#Modelo: GaussianNB
#Mejor combinación de hiperparámetros: {}
#Mejor puntuación de validación cruzada: 0.95592635305067
modelo_gaussian = GaussianNB() #  modelo creado con el algoritmo gaussian
#Modelo: GradientBoostingClassifier
#Mejor combinación de hiperparámetros: {'learning_rate': 0.1, 'loss': 'deviance', 'n_estimators': 200}
#Mejor puntuación de validación cruzada: 0.9863671160915264
modelo_Gradient_Boosting = GradientBoostingClassifier(learning_rate = 0.1,
                                                      loss="deviance",
                                                      n_estimators=200) #modelo creado con el algoritmo Gradient Boosting

modelos = [modelo_regression_logistica, modelo_decision_tree, modelo_random_forest, modelo_gaussian, modelo_Gradient_Boosting]

for modelo in modelos:
  print(modelo.fit(X_test, Y_test.values.ravel()))

"""Gridsearch
NO ejecutar
"""

# Grid Search
from sklearn.model_selection import GridSearchCV

# Definir los hiperparámetros y sus posibles valores
parametros = [{'penalty': [None,'l2'], #parametros de regresion logistica
              'C': [0.1, 1, 10, 100],
              'solver': ['sag', 'saga']},
              {'max_depth': [3, 5, 10, None], #parametros de decision tree
              'criterion': ['gini', 'entropy'],
              'max_features': ['auto', 'sqrt', 'log2', None]},
              {'n_estimators': [10, 50, 100, 150, 200, 250, 300], #parametros de random forest
              'criterion': ['gini', 'entropy'],
              'max_depth': [3, 5, None]},
              {},#parametros de gaussian ( no tiene )
              {'loss': ['deviance', 'exponential'], #parametros de Gradient Boosting Classifier
               'learning_rate': [0.01, 0.1, 1.0],
               'n_estimators': [50, 100, 200]}
              ]

grid_search = []
for i, modelo in enumerate(modelos):
  grid_search.append(GridSearchCV(modelo, param_grid=parametros[i], cv = 5))
print(grid_search)

#ejecutamos la busqueda de rejilla

for i,grid in enumerate(grid_search):
  grid.fit(X_test, Y_test.values.ravel())
  print(f"Modelo: {modelos[i].__class__.__name__}")
  print("Mejor combinación de hiperparámetros:", grid.best_params_)
  print("Mejor puntuación de validación cruzada:", grid.best_score_)

"""



Análisis de calidad del modelo generado"""

Y_predict = []
score_regression = []
sensibilidad = []
score_f1 = []
especificidad = []

for i, modelo in enumerate(modelos):


  Y_predict.append(modelo.predict(X_test)) # Hacemos predicciones con los datos de test

  # Obtenemos la precisión del modelo usando los datos predichos por el modelo y los datos reales
  score_regression.append(accuracy_score(Y_test,Y_predict[i])) # Usamos accuracy_score de sklearn metrics

  # Obtener la sensibilidad del modelo, mide la proporción de verdaderos positivos que son identificados correctamente
  sensibilidad.append(recall_score(Y_test,Y_predict[i])) # Usamos recall_score de sklearn metrics

  # Podemos usar f1-score que es una medida que combina la dos anteriores y mide la calidad global del modelo
  score_f1.append(f1_score(Y_test,Y_predict[i])) # Usamos f1_score de sklearn metrics

  print(f"\nModelo = {modelo.__class__.__name__}\nPrecision = {score_regression[i]} \nRecall = {sensibilidad[i]}\nF1 = {score_f1[i]}")

  #Matriz de confusion y especificidad
  tn, fp, fn, tp = confusion_matrix(Y_test, Y_predict[i]).ravel()
  especificidad.append(tn / (tn + fp))
  print("Especificidad:", especificidad[i])

  # Calcular el average precision score en el conjunto de prueba
  y_pred_proba = (modelo.predict_proba(X_test)[:, 1])  # Probabilidad de la clase positiv

  average_precision = (average_precision_score(Y_test, y_pred_proba)) #obtenemos el average precision score
  Falsos_Positivos, Verdaderos_Positivos, umbral_1 = roc_curve(Y_test, Y_predict[i])
  Curva_Roc= RocCurveDisplay(fpr = Falsos_Positivos,
                                        tpr = Verdaderos_Positivos,
                                        roc_auc = average_precision,
                                        estimator_name = "ROC")
  Curva_Roc.plot()

  precision, recall, _ = precision_recall_curve(Y_test, Y_predict[i]) # Raya al piso porque no nos sirve el umbral

  Visual = PrecisionRecallDisplay(precision, recall)
  Visual.plot(color = "b")
  plt.show()

#Diagrama de Araña
labels = ['Precision', 'Sensibilidad', 'Especificidad', 'Puntaje F1']
variables = []
metricas = []
grupos = []

for i, modelo in enumerate(modelos):
  metricas.append(score_regression[i])
  metricas.append(sensibilidad[i])
  metricas.append(especificidad[i])
  metricas.append(score_f1[i])

  variables = variables+labels
  grupos = grupos+[modelo.__class__.__name__]*len(labels)

df = pd.DataFrame(dict(
    valor = metricas,
    variable = variables,
    grupo = grupos))

fig = px.line_polar(df, r = 'valor', theta = 'variable', line_close = True,
                    color= 'grupo')
fig.show()

# Guardamos el modelo creado
joblib.dump(modelo, 'modelo_entrenado_regresion_logistica.pkl')